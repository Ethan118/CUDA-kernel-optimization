{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"execution":{"iopub.execute_input":"2023-10-16T04:08:25.691547Z","iopub.status.busy":"2023-10-16T04:08:25.691236Z","iopub.status.idle":"2023-10-16T04:08:26.769098Z","shell.execute_reply":"2023-10-16T04:08:26.767796Z","shell.execute_reply.started":"2023-10-16T04:08:25.691521Z"},"id":"zFuxPWe8PnM_","outputId":"ea5d7ce7-307c-4cb8-ac85-bd2d352e9bae","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Oct 16 04:08:26 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n","| N/A   46C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# This should say you're using a GPU.\n","# If you aren't using a GPU, go to \"Runtime\",\n","# then select \"change runtime type\" and click\n","# T4 GPU.\n","\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0r8ZHguJRTKj","outputId":"0c89d89b-6bb1-4083-bef8-006a75653496","trusted":true},"outputs":[],"source":["!git clone https://github.com/WAT-ai/kernel_tuner"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DfYGDguKSan6","outputId":"1cda4f30-85a3-4c8b-9f12-633aa4366af6","trusted":true},"outputs":[],"source":["!pip install kernel_tuner[cuda]"]},{"cell_type":"markdown","metadata":{"id":"idUV5FnqA2-z"},"source":["### Enhancing Convolution Operations with Correctness Verification\n","\n","In the context of computational operations utilizing convolution kernels, this example operates on a framework that largely mirrors a standard Convolution example. However, a nuanced distinction emerges in the strategic utilization of a naive kernel to establish a reference output. This output subsequently assumes a pivotal role, serving as a benchmark to verify the correctness of each kernel before its performance is benchmarked.\n","\n","Here's a breakdown of the process without code examples:\n","\n","1. **Kernel and Data Initialization**:\n","    - The kernel code is fetched from a predefined file and various data, including filter sizes and problem sizes, is initialized.\n","    - Input data and filters are set up and computational arguments are defined to facilitate subsequent operations.\n","  \n","2. **Parameter Tuning Setup**:\n","    - A structured collection of tuning parameters is configured, comprising diverse block and tile sizes.\n","    - Options to utilize or omit padding and the read-only cache are incorporated, providing versatile tuning capabilities.\n","\n","3. **Reference Output Generation**:\n","    - A naive convolution kernel is executed, wielding pre-specified parameters, to generate a reference output.\n","    - This output is crucial as it functions as a benchmark for accuracy in subsequent operations.\n","\n","4. **Verification and Kernel Tuning**:\n","    - An 'answer' list is set up, which marks input data as `None` and utilizes non-`None` data for verification purposes.\n","    - The `tune_kernel` function is invoked to tune the kernel, parallely cross-verifying each kernel in the parameter space against the pre-established reference output.\n","   \n","This methodology pivots around utilizing a naive kernel to derive a reference output and subsequently leveraging it for correctness checks during convolution operations, all before performance benchmarking occurs. This ensures computational reliability as it guarantees that only kernels which have been validated for correctness are subjected to the tuning and optimization phase."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-16T04:14:59.316951Z","iopub.status.busy":"2023-10-16T04:14:59.316552Z","iopub.status.idle":"2023-10-16T04:15:36.080348Z","shell.execute_reply":"2023-10-16T04:15:36.079388Z","shell.execute_reply.started":"2023-10-16T04:14:59.316922Z"},"id":"yrnSj1WGRcgQ","outputId":"ea5028e5-6cc1-4a11-f1ae-a3d77f99a846","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using: Tesla T4\n","Using: Tesla T4\n","skipping config 17_17_64_16_4_4_0_0 reason: too much shared memory used\n","skipping config 17_17_64_16_4_4_0_0 reason: too much shared memory used\n","filter_width=17, filter_height=17, block_size_x=64, block_size_y=16, tile_size_x=4, tile_size_y=4, use_padding=0, read_only=0, time=CompilationFailedConfig\n","filter_width=17, filter_height=17, block_size_x=80, block_size_y=2, tile_size_x=4, tile_size_y=2, use_padding=0, read_only=1, time=9.727ms\n","filter_width=17, filter_height=17, block_size_x=112, block_size_y=2, tile_size_x=1, tile_size_y=4, use_padding=1, read_only=1, time=6.349ms\n","filter_width=17, filter_height=17, block_size_x=16, block_size_y=8, tile_size_x=1, tile_size_y=4, use_padding=1, read_only=0, time=8.633ms\n","filter_width=17, filter_height=17, block_size_x=64, block_size_y=4, tile_size_x=2, tile_size_y=4, use_padding=0, read_only=0, time=6.300ms\n","max_fevals reached\n","best performing configuration:\n","filter_width=17, filter_height=17, block_size_x=64, block_size_y=4, tile_size_x=2, tile_size_y=4, use_padding=0, read_only=0, time=6.300ms\n","([OrderedDict([('filter_width', 17), ('filter_height', 17), ('block_size_x', 64), ('block_size_y', 16), ('tile_size_x', 4), ('tile_size_y', 4), ('use_padding', 0), ('read_only', 0), ('time', CompilationFailedConfig), ('compile_time', 12960.133123999982), ('verification_time', 0), ('benchmark_time', 0), ('strategy_time', 35.25438799999847), ('framework_time', 0.4663840001085191), ('timestamp', '2023-10-16 04:15:26.933562+00:00')]), OrderedDict([('filter_width', 17), ('filter_height', 17), ('block_size_x', 80), ('block_size_y', 2), ('tile_size_x', 4), ('tile_size_y', 2), ('use_padding', 0), ('read_only', 1), ('time', 9.726564407348633), ('times', [9.744319915771484, 9.738112449645996, 9.711615562438965, 9.711647987365723, 9.717791557312012, 9.732383728027344, 9.730079650878906]), ('compile_time', 2810.3804119999722), ('verification_time', 189.93763399998898), ('benchmark_time', 68.68322799994075), ('strategy_time', 0.013043999956607877), ('framework_time', 1.0192930001267086), ('timestamp', '2023-10-16 04:15:30.003644+00:00')]), OrderedDict([('filter_width', 17), ('filter_height', 17), ('block_size_x', 112), ('block_size_y', 2), ('tile_size_x', 1), ('tile_size_y', 4), ('use_padding', 1), ('read_only', 1), ('time', 6.349065099443708), ('times', [6.367199897766113, 6.3651838302612305, 6.349887847900391, 6.353663921356201, 6.33241605758667, 6.338592052459717, 6.336512088775635]), ('compile_time', 856.54174900003), ('verification_time', 191.11926899995524), ('benchmark_time', 45.05036900002324), ('strategy_time', 0.010220000035587873), ('framework_time', 0.7173419999162434), ('timestamp', '2023-10-16 04:15:31.097119+00:00')]), OrderedDict([('filter_width', 17), ('filter_height', 17), ('block_size_x', 16), ('block_size_y', 8), ('tile_size_x', 1), ('tile_size_y', 4), ('use_padding', 1), ('read_only', 0), ('time', 8.632777214050293), ('times', [8.648736000061035, 8.649920463562012, 8.634367942810059, 8.637855529785156, 8.615936279296875, 8.628543853759766, 8.614080429077148]), ('compile_time', 1560.040582000056), ('verification_time', 188.87407399995482), ('benchmark_time', 61.051953999935904), ('strategy_time', 0.008551000064471737), ('framework_time', 0.9271949999174467), ('timestamp', '2023-10-16 04:15:32.908054+00:00')]), OrderedDict([('filter_width', 17), ('filter_height', 17), ('block_size_x', 64), ('block_size_y', 4), ('tile_size_x', 2), ('tile_size_y', 4), ('use_padding', 0), ('read_only', 0), ('time', 6.299908569880894), ('times', [6.321119785308838, 6.303616046905518, 6.295743942260742, 6.289408206939697, 6.291711807250977, 6.2942399978637695, 6.303520202636719]), ('compile_time', 2930.2946059999613), ('verification_time', 188.79806000006738), ('benchmark_time', 44.75874999991447), ('strategy_time', 0.007495999966522504), ('framework_time', 0.8492060001117352), ('timestamp', '2023-10-16 04:15:36.072798+00:00')])], {'device_name': 'Tesla T4', 'cuda_version': 11040, 'compute_capability': '75', 'iterations': 7, 'compiler_options': None, 'device_properties': {'AsyncEngineCount': 3, 'CanFlushRemoteWrites': 0, 'CanMapHostMemory': 1, 'CanUseHostPointerForRegisteredMem': 1, 'ClockRate': 1590000, 'ComputeMode': 0, 'ComputePreemptionSupported': 1, 'ConcurrentKernels': 1, 'ConcurrentManagedAccess': 1, 'CooperativeLaunch': 1, 'CooperativeMultiDeviceLaunch': 1, 'DirectManagedMemAccessFromHost': 0, 'EccEnabled': 1, 'GPUDirectRDMAFlushWritesOptions': 1, 'GPUDirectRDMASupported': 1, 'GPUDirectRDMAWritesOrdering': 0, 'GlobalL1CacheSupported': 1, 'GlobalMemoryBusWidth': 256, 'GpuOverlap': 1, 'HostNativeAtomicSupported': 0, 'HostRegisterReadOnlySupported': 1, 'HostRegisterSupported': 1, 'Integrated': 0, 'IsMultiGpuBoard': 0, 'KernelExecTimeout': 0, 'L2CacheSize': 4194304, 'LocalL1CacheSupported': 1, 'ManagedMemory': 1, 'MaxBlockDimX': 1024, 'MaxBlockDimY': 1024, 'MaxBlockDimZ': 64, 'MaxBlocksPerMultiprocessor': 16, 'MaxGridDimX': 2147483647, 'MaxGridDimY': 65535, 'MaxGridDimZ': 65535, 'MaxPitch': 2147483647, 'MaxRegistersPerBlock': 65536, 'MaxRegistersPerMultiprocessor': 65536, 'MaxSharedMemoryPerBlock': 49152, 'MaxSharedMemoryPerBlockOptin': 65536, 'MaxSharedMemoryPerMultiprocessor': 65536, 'MaxSurface1DLayeredLayers': 2048, 'MaxSurface1DLayeredWidth': 32768, 'MaxSurface1DWidth': 32768, 'MaxSurface2DHeight': 65536, 'MaxSurface2DLayeredHeight': 32768, 'MaxSurface2DLayeredLayers': 2048, 'MaxSurface2DLayeredWidth': 32768, 'MaxSurface2DWidth': 131072, 'MaxSurface3DDepth': 16384, 'MaxSurface3DHeight': 16384, 'MaxSurface3DWidth': 16384, 'MaxSurfaceCubemapLayeredLayers': 2046, 'MaxSurfaceCubemapLayeredWidth': 32768, 'MaxSurfaceCubemapWidth': 32768, 'MaxTexture1DLayeredLayers': 2048, 'MaxTexture1DLayeredWidth': 32768, 'MaxTexture1DLinearWidth': 268435456, 'MaxTexture1DMipmappedWidth': 32768, 'MaxTexture1DWidth': 131072, 'MaxTexture2DGatherHeight': 32768, 'MaxTexture2DGatherWidth': 32768, 'MaxTexture2DHeight': 65536, 'MaxTexture2DLayeredHeight': 32768, 'MaxTexture2DLayeredLayers': 2048, 'MaxTexture2DLayeredWidth': 32768, 'MaxTexture2DLinearHeight': 65000, 'MaxTexture2DLinearPitch': 2097120, 'MaxTexture2DLinearWidth': 131072, 'MaxTexture2DMipmappedHeight': 32768, 'MaxTexture2DMipmappedWidth': 32768, 'MaxTexture2DWidth': 131072, 'MaxTexture3DDepth': 16384, 'MaxTexture3DDepthAlt': 32768, 'MaxTexture3DHeight': 16384, 'MaxTexture3DHeightAlt': 8192, 'MaxTexture3DWidth': 16384, 'MaxTexture3DWidthAlt': 8192, 'MaxTextureCubemapLayeredLayers': 2046, 'MaxTextureCubemapLayeredWidth': 32768, 'MaxTextureCubemapWidth': 32768, 'MaxThreadsPerBlock': 1024, 'MaxThreadsPerMultiProcessor': 1024, 'MaxTimelineSemaphoreInteropSupported': 1, 'MemoryClockRate': 5001000, 'MemoryPoolSupportedHandleTypes': 1, 'MemoryPoolsSupported': 1, 'MultiGpuBoardGroupID': 0, 'MultiProcessorCount': 40, 'PageableMemoryAccess': 0, 'PageableMemoryAccessUsesHostPageTables': 0, 'PciBusId': 0, 'PciDeviceId': 4, 'PciDomainId': 0, 'Reserved92': 0, 'Reserved93': 0, 'Reserved94': 0, 'ReservedSharedMemoryPerBlock': 0, 'SingleToDoublePrecisionPerfRatio': 32, 'SparseCudaArraySupported': 1, 'StreamPrioritiesSupported': 1, 'SurfaceAlignment': 512, 'TccDriver': 0, 'TextureAlignment': 512, 'TexturePitchAlignment': 32, 'TotalConstantMemory': 65536, 'UnifiedAddressing': 1, 'WarpSize': 32}, 'total_framework_time': 3.979420000180653, 'total_strategy_time': 35.29369900002166, 'total_compile_time': 21117.390473, 'total_verification_time': 758.7290369999664, 'total_benchmark_time': 219.54430099981437, 'overhead_time': 13905.937397000002})\n","\n"," Actual time used: 36748.953857421875\n"]}],"source":["import numpy\n","import kernel_tuner\n","from collections import OrderedDict\n","from kernel_tuner.strategies import *\n","\n","def tune():\n","    with open(\"kernel_tuner/examples/cuda/convolution.cu\", \"r\") as f:\n","        kernel_string = f.read()\n","\n","    filter_size = (17, 17)\n","    problem_size = (4096, 4096)\n","    size = numpy.prod(problem_size)\n","    border_size = (filter_size[0] // 2 * 2, filter_size[1] // 2 * 2)\n","    input_size = (problem_size[0] + border_size[0]) * (problem_size[1] + border_size[1])\n","\n","    output = numpy.zeros(size).astype(numpy.float32)\n","    input = numpy.random.randn(input_size).astype(numpy.float32)\n","\n","    filter = numpy.random.randn(filter_size[0] * filter_size[1]).astype(numpy.float32)\n","    cmem_args = {\"d_filter\": filter}\n","\n","    args = [output, input, filter]\n","    tune_params = OrderedDict()\n","    tune_params[\"filter_width\"] = [filter_size[0]]\n","    tune_params[\"filter_height\"] = [filter_size[1]]\n","\n","    # tune_params[\"block_size_x\"] = [16*i for i in range(1,3)]\n","    tune_params[\"block_size_x\"] = [16 * i for i in range(1, 9)]\n","    # tune_params[\"block_size_y\"] = [2**i for i in range(1,5)]\n","    tune_params[\"block_size_y\"] = [2**i for i in range(1, 6)]\n","\n","    tune_params[\"tile_size_x\"] = [2**i for i in range(3)]\n","    tune_params[\"tile_size_y\"] = [2**i for i in range(3)]\n","\n","    tune_params[\"use_padding\"] = [\n","        0,\n","        1,\n","    ]  # toggle the insertion of padding in shared memory\n","    tune_params[\"read_only\"] = [0, 1]  # toggle using the read-only cache\n","\n","    grid_div_x = [\"block_size_x\", \"tile_size_x\"]\n","    grid_div_y = [\"block_size_y\", \"tile_size_y\"]\n","\n","    # compute the answer using a naive kernel\n","    params = {\"block_size_x\": 16, \"block_size_y\": 16}\n","    tune_params[\"filter_width\"] = [filter_size[0]]\n","    tune_params[\"filter_height\"] = [filter_size[1]]\n","    results = kernel_tuner.run_kernel(\n","        \"convolution_naive\",\n","        kernel_string,\n","        problem_size,\n","        args,\n","        params,\n","        grid_div_y=[\"block_size_y\"],\n","        grid_div_x=[\"block_size_x\"],\n","        lang=\"cupy\",\n","    )\n","\n","    # set non-output fields to None\n","    answer = [results[0], None, None]\n","\n","    # start kernel tuning with correctness verification\n","    return kernel_tuner.tune_kernel(\n","        \"convolution_kernel\",\n","        kernel_string,\n","        problem_size,\n","        args,\n","        tune_params,\n","        grid_div_y=grid_div_y,\n","        grid_div_x=grid_div_x,\n","        verbose=True,\n","        cmem_args=cmem_args,\n","        answer=answer,\n","        lang=\"cupy\",\n","        strategy=\"genetic_algorithm\",\n","        strategy_options=dict(max_fevals=5)\n","    )\n","\n","def numpy_int64_to_int(obj):\n","    if isinstance(obj, numpy.int64):\n","        return int(obj)\n","    raise TypeError\n","\n","if __name__ == \"__main__\":\n","    import time\n","\n","    s1 = time.time() * 1000\n","    results = tune()\n","    print(results)\n","\n","    e1 = time.time() * 1000\n","    print(\"\\n Actual time used:\", e1 - s1)\n","    import json\n","\n","    with open(\"convolution_gpu_runtime.json\", \"w\") as fp:\n","        json.dump(results, fp, default=numpy_int64_to_int)\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
